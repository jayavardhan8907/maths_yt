import streamlit as st
from dotenv import load_dotenv
import os
import google.generativeai as genai
from youtube_transcript_api import YouTubeTranscriptApi
import boto3
import tempfile
from pytube import YouTube
import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline

load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# AWS S3 Configuration
aws_access_key = "AKIA4YUIBKK5PFVX2VMA"
aws_secret_key = "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"
bucket_name = "maths1yt"
s3 = boto3.client("s3", aws_access_key_id=aws_access_key, aws_secret_access_key=aws_secret_key)

# Set Hugging Face Token
os.environ['HF_TOKEN'] = "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"

prompt = """You are Yotube video summarizer. You will be taking the transcript text
and summarizing the entire video and providing the important summary in points
within 250 words. Please provide the summary of the text given here: """

def download_audio_from_youtube(youtube_link):
    video = YouTube(youtube_link)
    video_id = video.video_id
    # Download the highest quality audio stream
    audio_stream = video.streams.filter(only_audio=True).order_by('abr').desc().first()
    audio_file = audio_stream.download(filename=f"{video_id}.mp3")
    st.write("Audio downloaded successfully.")
    return audio_file

def upload_audio_to_s3(audio_file):
    with open(audio_file, 'rb') as data:
        s3.upload_fileobj(data, bucket_name, audio_file)
    st.write("Audio uploaded to AWS S3.")
    return f"https://{bucket_name}.s3.amazonaws.com/{audio_file}"

def speech2text(mp3_file):
    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32
    model_id = "distil-whisper/distil-large-v2"
    model = AutoModelForSpeechSeq2Seq.from_pretrained(model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True, use_flash_attention_2=True)
    model.to(device)
    processor = AutoProcessor.from_pretrained(model_id)
    pipe = pipeline("automatic-speech-recognition", model=model, tokenizer=processor.tokenizer, feature_extractor=processor.feature_extractor, max_new_tokens=128, chunk_length_s=15, batch_size=16, torch_dtype=torch_dtype, device=device)
    result = pipe(mp3_file)
    text_from_video = result["text"]
    return text_from_video

def generate_gemini_content(transcript_text, prompt):
    model = genai.GenerativeModel("gemini-pro")
    response = model.generate_content(prompt + transcript_text)
    st.write("Content generated by Gemini model.")
    return response.text

st.title("YouTube Transcript to Detailed Notes Converter")
youtube_link = st.text_input("Enter YouTube Video Link:")

if youtube_link:
    video_id = youtube_link.split("=")[1]
    st.image(f"http://img.youtube.com/vi/{video_id}/0.jpg", use_column_width=300)

if st.button("Get Detailed Notes"):
    with st.spinner('Processing video...'):
        audio_file = download_audio_from_youtube(youtube_link)
        audio_uri = upload_audio_to_s3(audio_file)
        transcript_text = speech2text(audio_file) # Use the new speech2text function
        summary = generate_gemini_content(transcript_text, prompt)
        st.markdown("## Detailed Notes:")
        st.write(summary)
